{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa508bb6",
   "metadata": {},
   "source": [
    "## Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb811a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import sys\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from collections import namedtuple\n",
    "\n",
    "# Torch utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8647ccbf",
   "metadata": {},
   "source": [
    "**Remember conversions**\n",
    "* 8 Bits = 1 Byte\n",
    "* 8192 Bits = 1024 Bytes = 1 Kb.\n",
    "* 8388608 Bits = 1048576 Bytes = 1 Mb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ff2c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object to store info about parameters in network\n",
    "Parameter = namedtuple('Parameter', ['size', 'bits'],\n",
    "                       defaults=[np.asarray((0, 0)), 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71d8b02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 128, 128])\n",
      "torch.float32\n",
      "100663296\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.FloatTensor(64, 3, 128, 128)\n",
    "input_tensor.requires_grad = True\n",
    "\n",
    "print(input_tensor.size())\n",
    "print(input_tensor.dtype)\n",
    "print(np.prod(input_tensor.size()) * 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dbe2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor.grad  # == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe38c19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Variable(input_tensor, requires_grad=True) \n",
    "out = input_tensor + input_tensor\n",
    "out.backward(input_tensor)\n",
    "print(input_tensor.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eed47590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 128, 128])\n",
      "torch.float32\n",
      "100663296\n"
     ]
    }
   ],
   "source": [
    "# Grad\n",
    "print(input_tensor.grad.size())\n",
    "print(input_tensor.grad.dtype)\n",
    "print(np.prod(input_tensor.grad.size()) * 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a25cee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizeEstimator:\n",
    "\n",
    "    def __init__(self, model: nn.Module, input_size: List[int],\n",
    "                 input_n_bits: int = 32):\n",
    "        \"\"\"\n",
    "        Estimates the size of PyTorch models in memory\n",
    "        for a given input size and data precision, measured in bits.\n",
    "        So default input type of torch.float32 equals to 32 bits precision.\n",
    "        \"\"\"\n",
    "        self._model = model\n",
    "        self._input_size = input_size\n",
    "        self._input_n_bits = input_n_bits\n",
    "\n",
    "        # Calculate\n",
    "        self._parameters_sizes = self._get_parameter_sizes()\n",
    "        self._output_sizes = self._get_output_sizes()\n",
    "        self._parameters_bits = self._calculate_parameters_weight()\n",
    "        self._forward_backward_bits = self._calculate_forward_backward_weight()\n",
    "        self._input_weight = self._calculate_input_weight()\n",
    "\n",
    "    def _get_parameter_sizes(self) -> List[Parameter]:\n",
    "        \"\"\"\n",
    "        Get sizes of all parameters in `model`\n",
    "        \"\"\"\n",
    "        sizes = []\n",
    "        modules = list(self._model.modules())[1:]\n",
    "        for i, module in enumerate(modules):\n",
    "            if isinstance(module, nn.ModuleList):\n",
    "                # To not to estimate inner sub-modules twice!\n",
    "                continue\n",
    "            else:\n",
    "                sizes.extend([Parameter(size=np.asarray(param.size(), dtype=np.float64),\n",
    "                                        bits=self.__get_parameter_bits(param))\n",
    "                              for param in module.parameters()])\n",
    "        return sizes\n",
    "\n",
    "    def _get_output_sizes(self) -> List[Parameter]:\n",
    "        \"\"\"\n",
    "        Run sample input through each layer to get output sizes\n",
    "        \"\"\"\n",
    "        input_ = torch.Tensor(torch.FloatTensor(*self._input_size))  #, volatile=True\n",
    "        modules = list(self._model.modules())[1:]\n",
    "        out_sizes = []\n",
    "        for i, module in enumerate(modules):\n",
    "            out = module(input_)\n",
    "            out_sizes.append(Parameter(size=np.asarray(out.size(), dtype=np.float64),\n",
    "                                       bits=self.__get_parameter_bits(out)))\n",
    "            input_ = out\n",
    "        return out_sizes\n",
    "\n",
    "    def _calculate_parameters_weight(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculate total number of bits to store `model` parameters\n",
    "        \"\"\"\n",
    "        total_bits = 0\n",
    "        for param in self._parameters_sizes:\n",
    "            total_bits += np.prod(param.size) * param.bits\n",
    "        return total_bits\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_parameter_bits(param: torch.Tensor) -> int:\n",
    "        \"\"\"\n",
    "        Calculate total number of bits to store `model` parameters\n",
    "        \"\"\"\n",
    "        # Choose dtype\n",
    "        if param.dtype == torch.float16:\n",
    "            return 16\n",
    "        elif param.dtype == torch.bfloat16:\n",
    "            return 16\n",
    "        elif param.dtype == torch.float32:\n",
    "            return 32\n",
    "        elif param.dtype == torch.float64:\n",
    "            return 64\n",
    "        else:\n",
    "            print(f\"Current version estimated only sizes of floating points parameters!\")\n",
    "            return 32\n",
    "\n",
    "    def _calculate_forward_backward_weight(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculate bits to store forward and backward pass\n",
    "        \"\"\"\n",
    "        total_bits = 0\n",
    "        for out in self._output_sizes:\n",
    "            # forward pass\n",
    "            f_bits = np.prod(out.size) * out.bits\n",
    "            total_bits += f_bits\n",
    "\n",
    "        # Multiply by 2 for both forward and backward\n",
    "        return total_bits * 2\n",
    "\n",
    "    def _calculate_input_weight(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculate bits to store single input sequence.\n",
    "        \"\"\"\n",
    "        return np.prod(np.array(self._input_size, dtype=np.float64)) * self._input_n_bits\n",
    "\n",
    "    def estimate_total_size(self) -> float:\n",
    "        \"\"\"\n",
    "        Estimate model size in memory in megabytes and bits.\n",
    "        \"\"\"\n",
    "        total = self._input_weight + self._parameters_bits + self._forward_backward_bits\n",
    "        total_bytes = (total / 8)\n",
    "        total_megabytes = total_bytes / (1024**2)\n",
    "        print(f\"Model size is: {total} bits, {total_bytes} bytes, {total_megabytes} Mb.\")\n",
    "        return total_megabytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db8ca06",
   "metadata": {},
   "source": [
    "## Example #1: Simple convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9101e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(1, 16, kernel_size=3, padding=5)\n",
    "        self.conv1 = nn.Conv2d(16, 32, kernel_size=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv0(x)\n",
    "        h = self.conv1(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b391f794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleModel(\n",
      "  (conv0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(5, 5))\n",
      "  (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "simple_net = SimpleModel()\n",
    "sample_input = torch.FloatTensor(64, 1, 128, 128)\n",
    "print(simple_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca9b2d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size is: 3599390720.0 bits, 449923840.0 bytes, 429.080810546875 Mb.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "429.080810546875"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = SizeEstimator(model=simple_net, \n",
    "                          input_size=sample_input.size(),\n",
    "                          input_n_bits=32)  # as input type is float32\n",
    "estimator.estimate_total_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc4482e",
   "metadata": {},
   "source": [
    "## Example #2: Model with nested nn.ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c74f9aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputSize, numLayers, nodesPerLayer):\n",
    "        super(NestedModel, self).__init__()\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        self.hidden.append(nn.Linear(inputSize, nodesPerLayer))\n",
    "        for i in range(numLayers-1):\n",
    "            self.hidden.append(nn.Linear(nodesPerLayer, nodesPerLayer))\n",
    "        self.finalFC = nn.Linear(nodesPerLayer, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.finalFC(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "276acb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NestedModel(\n",
      "  (activation): Sigmoid()\n",
      "  (hidden): ModuleList(\n",
      "    (0): Linear(in_features=200, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (5): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (finalFC): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "nested_model = NestedModel(inputSize=200, numLayers=8, nodesPerLayer=128)\n",
    "sample_input = torch.FloatTensor(64, 100, 200)\n",
    "print(nested_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a2fe66d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-d39924da4926>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m estimator = SizeEstimator(model=nested_model, \n\u001b[0;32m      2\u001b[0m                           \u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                           input_n_bits=32)  # as input type is float32\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate_total_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-e642a100b897>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, input_size, input_n_bits)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Calculate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameters_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_parameter_sizes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_output_sizes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameters_bits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calculate_parameters_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_backward_bits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calculate_forward_backward_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-e642a100b897>\u001b[0m in \u001b[0;36m_get_output_sizes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mout_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             out_sizes.append(Parameter(size=np.asarray(out.size(), dtype=np.float64),\n\u001b[0;32m     47\u001b[0m                                        bits=self.__get_parameter_bits(out)))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\eyeverif\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\eyeverif\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \"\"\"\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator = SizeEstimator(model=nested_model, \n",
    "                          input_size=sample_input.size(),\n",
    "                          input_n_bits=32)  # as input type is float32\n",
    "estimator.estimate_total_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5ce0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
